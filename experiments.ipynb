{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./mpt-gsm8k-dense/training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- HERE: INITIALIZE MODEL -----\n",
      "You are using config.init_device='cpu', but you can also use config.init_device=\"meta\" with Composer + FSDP for fast initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5bb75bd4555247d6a5befa75d4a3b861",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "mpt = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpt.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?Weng earns $12/hour * 50 minutes = $<<12*50=600>>600 for babysitting.\n",
      "#### 600<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = mpt.generate(**inputs, max_new_tokens=50, eos_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.batch_decode(generated_ids)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sparsity(model):\n",
    "    print(\"Sparsity distribution:\")\n",
    "    for n, m in model.named_parameters():\n",
    "        print(f\"{n} = {torch.sum(m == 0)/m.numel() * 100:.2f} %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity distribution:\n",
      "transformer.wte.weight = 0.00 %\n",
      "transformer.blocks.0.norm_1.weight = 0.00 %\n",
      "transformer.blocks.0.attn.Wqkv.weight = 0.00 %\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "transformer.blocks.0.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.0.norm_2.weight = 0.00 %\n",
      "transformer.blocks.0.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.0.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.1.norm_1.weight = 0.00 %\n",
      "transformer.blocks.1.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.1.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.1.norm_2.weight = 0.00 %\n",
      "transformer.blocks.1.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.1.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.2.norm_1.weight = 0.00 %\n",
      "transformer.blocks.2.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.2.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.2.norm_2.weight = 0.00 %\n",
      "transformer.blocks.2.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.2.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.3.norm_1.weight = 0.00 %\n",
      "transformer.blocks.3.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.3.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.3.norm_2.weight = 0.00 %\n",
      "transformer.blocks.3.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.3.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.4.norm_1.weight = 0.00 %\n",
      "transformer.blocks.4.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.4.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.4.norm_2.weight = 0.00 %\n",
      "transformer.blocks.4.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.4.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.5.norm_1.weight = 0.00 %\n",
      "transformer.blocks.5.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.5.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.5.norm_2.weight = 0.00 %\n",
      "transformer.blocks.5.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.5.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.6.norm_1.weight = 0.00 %\n",
      "transformer.blocks.6.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.6.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.6.norm_2.weight = 0.00 %\n",
      "transformer.blocks.6.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.6.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.7.norm_1.weight = 0.00 %\n",
      "transformer.blocks.7.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.7.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.7.norm_2.weight = 0.00 %\n",
      "transformer.blocks.7.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.7.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.8.norm_1.weight = 0.00 %\n",
      "transformer.blocks.8.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.8.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.8.norm_2.weight = 0.00 %\n",
      "transformer.blocks.8.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.8.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.9.norm_1.weight = 0.00 %\n",
      "transformer.blocks.9.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.9.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.9.norm_2.weight = 0.00 %\n",
      "transformer.blocks.9.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.9.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.10.norm_1.weight = 0.00 %\n",
      "transformer.blocks.10.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.10.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.10.norm_2.weight = 0.00 %\n",
      "transformer.blocks.10.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.10.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.11.norm_1.weight = 0.00 %\n",
      "transformer.blocks.11.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.11.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.11.norm_2.weight = 0.00 %\n",
      "transformer.blocks.11.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.11.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.12.norm_1.weight = 0.00 %\n",
      "transformer.blocks.12.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.12.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.12.norm_2.weight = 0.00 %\n",
      "transformer.blocks.12.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.12.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.13.norm_1.weight = 0.00 %\n",
      "transformer.blocks.13.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.13.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.13.norm_2.weight = 0.00 %\n",
      "transformer.blocks.13.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.13.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.14.norm_1.weight = 0.00 %\n",
      "transformer.blocks.14.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.14.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.14.norm_2.weight = 0.00 %\n",
      "transformer.blocks.14.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.14.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.15.norm_1.weight = 0.00 %\n",
      "transformer.blocks.15.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.15.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.15.norm_2.weight = 0.00 %\n",
      "transformer.blocks.15.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.15.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.16.norm_1.weight = 0.00 %\n",
      "transformer.blocks.16.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.16.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.16.norm_2.weight = 0.00 %\n",
      "transformer.blocks.16.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.16.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.17.norm_1.weight = 0.00 %\n",
      "transformer.blocks.17.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.17.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.17.norm_2.weight = 0.00 %\n",
      "transformer.blocks.17.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.17.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.18.norm_1.weight = 0.00 %\n",
      "transformer.blocks.18.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.18.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.18.norm_2.weight = 0.00 %\n",
      "transformer.blocks.18.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.18.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.19.norm_1.weight = 0.00 %\n",
      "transformer.blocks.19.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.19.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.19.norm_2.weight = 0.00 %\n",
      "transformer.blocks.19.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.19.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.20.norm_1.weight = 0.00 %\n",
      "transformer.blocks.20.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.20.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.20.norm_2.weight = 0.00 %\n",
      "transformer.blocks.20.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.20.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.21.norm_1.weight = 0.00 %\n",
      "transformer.blocks.21.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.21.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.21.norm_2.weight = 0.00 %\n",
      "transformer.blocks.21.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.21.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.22.norm_1.weight = 0.00 %\n",
      "transformer.blocks.22.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.22.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.22.norm_2.weight = 0.00 %\n",
      "transformer.blocks.22.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.22.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.23.norm_1.weight = 0.00 %\n",
      "transformer.blocks.23.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.23.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.23.norm_2.weight = 0.00 %\n",
      "transformer.blocks.23.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.23.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.24.norm_1.weight = 0.00 %\n",
      "transformer.blocks.24.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.24.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.24.norm_2.weight = 0.00 %\n",
      "transformer.blocks.24.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.24.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.25.norm_1.weight = 0.00 %\n",
      "transformer.blocks.25.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.25.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.25.norm_2.weight = 0.00 %\n",
      "transformer.blocks.25.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.25.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.26.norm_1.weight = 0.00 %\n",
      "transformer.blocks.26.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.26.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.26.norm_2.weight = 0.00 %\n",
      "transformer.blocks.26.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.26.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.27.norm_1.weight = 0.00 %\n",
      "transformer.blocks.27.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.27.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.27.norm_2.weight = 0.00 %\n",
      "transformer.blocks.27.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.27.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.28.norm_1.weight = 0.00 %\n",
      "transformer.blocks.28.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.28.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.28.norm_2.weight = 0.00 %\n",
      "transformer.blocks.28.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.28.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.29.norm_1.weight = 0.00 %\n",
      "transformer.blocks.29.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.29.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.29.norm_2.weight = 0.00 %\n",
      "transformer.blocks.29.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.29.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.30.norm_1.weight = 0.00 %\n",
      "transformer.blocks.30.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.30.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.30.norm_2.weight = 0.00 %\n",
      "transformer.blocks.30.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.30.ffn.down_proj.weight = 0.00 %\n",
      "transformer.blocks.31.norm_1.weight = 0.00 %\n",
      "transformer.blocks.31.attn.Wqkv.weight = 0.00 %\n",
      "transformer.blocks.31.attn.out_proj.weight = 0.00 %\n",
      "transformer.blocks.31.norm_2.weight = 0.00 %\n",
      "transformer.blocks.31.ffn.up_proj.weight = 0.00 %\n",
      "transformer.blocks.31.ffn.down_proj.weight = 0.00 %\n",
      "transformer.norm_f.weight = 0.00 %\n",
      "lm_head.weight = 0.00 %\n"
     ]
    }
   ],
   "source": [
    "print_sparsity(mpt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmagicml.research.sparsegpt.modelutils import (\n",
    "    apply_recipe, \n",
    "    initialize_scales_from_batches, \n",
    "    find_quant_layers, \n",
    "    find_layers, \n",
    "    freeze_bn_stats\n",
    ")\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class SparseGPTConfig:\n",
    "    nsamples = 128\n",
    "    sparsity = 0.5\n",
    "    minlayer = -1\n",
    "    maxlayer = 100\n",
    "    prune_only = \"\"\n",
    "    invert = False\n",
    "    prune_n = 0\n",
    "    prune_m = 0\n",
    "    perc_damp = 0.01\n",
    "    blocksize = 128\n",
    "    ptq = False\n",
    "\n",
    "sparsegpt_config = SparseGPTConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 7473\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "MAX_SEQ_LEN = 512\n",
    "\n",
    "def tokenize_fn(element):\n",
    "    text = f'{element[\"question\"]} {element[\"answer\"]}'\n",
    "\n",
    "    outputs = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_SEQ_LEN,\n",
    "        return_overflowing_tokens=False,\n",
    "        return_length=False,\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": outputs[\"input_ids\"],\n",
    "        \"attention_mask\": outputs[\"attention_mask\"]\n",
    "    }\n",
    "\n",
    "tokenized_dataset_train = train_dataset.map(\n",
    "    tokenize_fn,\n",
    "    batched=False,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    tokenized_dataset_train, \n",
    "    shuffle=True, \n",
    "    collate_fn=data_collator, \n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SparseGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmagicml.research.sparsegpt.sparsegpt import SparseGPT\n",
    "from neuralmagicml.research.sparsegpt.quant import WeightFakeQuantizer\n",
    "\n",
    "@torch.no_grad()\n",
    "def mpt_sequential(model, dataloader, data_seq_len, dev, cfg):\n",
    "    assert cfg.nsamples > 0, \"When using sparsegpt, nsamples must be > 0\"\n",
    "    NSAMPLES = cfg.nsamples\n",
    "    SPARSITY = cfg.sparsity\n",
    "    MINLAYER = cfg.minlayer\n",
    "    MAXLAYER = cfg.maxlayer\n",
    "    PRUNE_ONLY = cfg.prune_only\n",
    "    INVERT = cfg.invert\n",
    "    PRUNE_N = cfg.prune_n\n",
    "    PRUNE_M = cfg.prune_m\n",
    "    PERC_DAMP = cfg.perc_damp\n",
    "    BLOCKSIZE = cfg.blocksize\n",
    "\n",
    "    PTQ = cfg.ptq\n",
    "    print(f\"PTQ = {PTQ}\")\n",
    "    if PTQ:\n",
    "        model, manager = apply_recipe(model, cfg.recipe)\n",
    "        initialize_scales_from_batches(model, dataloader, cfg.observer_batches)\n",
    "\n",
    "    print(\"Starting ...\")\n",
    "\n",
    "    use_cache = model.config.use_cache\n",
    "    model.config.use_cache = False\n",
    "    layers = model.transformer.blocks\n",
    "\n",
    "    model.transformer.wte = model.transformer.wte.to(dev)\n",
    "    layers[0] = layers[0].to(dev)\n",
    "\n",
    "    dtype = next(iter(model.parameters())).dtype\n",
    "    inps = torch.zeros(\n",
    "        (NSAMPLES, data_seq_len, model.config.d_model), dtype=dtype, device=dev\n",
    "    )\n",
    "    cache = []\n",
    "    # cache_attn_mask = []\n",
    "\n",
    "    class Catcher(torch.nn.Module):\n",
    "        def __init__(self, module):\n",
    "            super().__init__()\n",
    "            self.module = module\n",
    "\n",
    "        def forward(self, inp, **kwargs):\n",
    "            inps[len(cache)] = inp\n",
    "            cache.append(kwargs[\"attn_bias\"])\n",
    "            raise ValueError\n",
    "\n",
    "    layers[0] = Catcher(layers[0])\n",
    "    i = 0\n",
    "    \n",
    "    for batch in iter(dataloader):\n",
    "        try:\n",
    "            tmp = {k: v.to(dev) for k, v in batch.items()}\n",
    "            # cache_attn_mask.append(tmp[\"attention_mask\"])\n",
    "            model(**tmp)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        i += 1\n",
    "        if i == NSAMPLES:\n",
    "            break\n",
    "    layers[0] = layers[0].module\n",
    "\n",
    "    layers[0] = layers[0].cpu()\n",
    "    model.transformer.wte = model.transformer.wte.cpu()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    outs = torch.zeros_like(inps)\n",
    "\n",
    "    print(\"Ready.\")\n",
    "\n",
    "    for i in range(len(layers)):\n",
    "        layer = layers[i].to(dev)\n",
    "        if PTQ:\n",
    "            # The layer names are changed due to quantization modifiers, therefore\n",
    "            # we need a slightly different func to retrieve layers\n",
    "            subset = find_quant_layers(layer)\n",
    "        else:\n",
    "            subset = find_layers(layer)\n",
    "\n",
    "        gpts = {}\n",
    "        for name in subset:\n",
    "            if (not (MINLAYER <= i < MAXLAYER and PRUNE_ONLY in name)) == (not INVERT):\n",
    "                continue\n",
    "            gpts[name] = SparseGPT(subset[name])\n",
    "            if PTQ:\n",
    "                gpts[name].quantizer = WeightFakeQuantizer(subset[name])\n",
    "\n",
    "        def add_batch(name):\n",
    "            def tmp(_, inp, out):\n",
    "                gpts[name].add_batch(inp[0].data, out.data)\n",
    "\n",
    "            return tmp\n",
    "\n",
    "        handles = []\n",
    "        for name in gpts:\n",
    "            handles.append(subset[name].register_forward_hook(add_batch(name)))\n",
    "        \n",
    "        for j in range(NSAMPLES):\n",
    "            outs[j] = layer(inps[j].unsqueeze(0), attn_bias=cache[j])[0]\n",
    "        for h in handles:\n",
    "            h.remove()\n",
    "\n",
    "        for name in gpts:\n",
    "            print(i, name)\n",
    "            print(\"Pruning ...\")\n",
    "            gpts[name].fasterprune(\n",
    "                SPARSITY,\n",
    "                prunen=PRUNE_N,\n",
    "                prunem=PRUNE_M,\n",
    "                percdamp=PERC_DAMP,\n",
    "                blocksize=BLOCKSIZE,\n",
    "            )\n",
    "            gpts[name].free()\n",
    "\n",
    "        for j in range(NSAMPLES):\n",
    "            outs[j] = layer(inps[j].unsqueeze(0), attn_bias=cache[j])[0]\n",
    "\n",
    "        layers[i] = layer.cpu()\n",
    "        del layer\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        inps, outs = outs, inps\n",
    "\n",
    "    print(model)\n",
    "    model.apply(torch.quantization.disable_observer)\n",
    "    model.apply(freeze_bn_stats)\n",
    "    model.config.use_cache = use_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ = False\n",
      "Starting ...\n",
      "Ready.\n",
      "0 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.91\n",
      "error 25.434906005859375\n",
      "0 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 18.28067398071289\n",
      "0 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 4068.03173828125\n",
      "0 ffn.down_proj\n",
      "Pruning ...\n",
      "time 3.98\n",
      "error 12.001224517822266\n",
      "1 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.30\n",
      "error 232.1502685546875\n",
      "1 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 10.658576965332031\n",
      "1 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 5781.634765625\n",
      "1 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.07\n",
      "error 12.84139347076416\n",
      "2 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.35\n",
      "error 394.74127197265625\n",
      "2 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 52.782859802246094\n",
      "2 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 6154.84033203125\n",
      "2 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.06\n",
      "error 61.63454818725586\n",
      "3 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.35\n",
      "error 772.435546875\n",
      "3 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 19.284317016601562\n",
      "3 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 9611.99609375\n",
      "3 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.12\n",
      "error 41.04884719848633\n",
      "4 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.37\n",
      "error 1467.7095947265625\n",
      "4 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 38.02000427246094\n",
      "4 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 10461.02734375\n",
      "4 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.13\n",
      "error 60.27094268798828\n",
      "5 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.38\n",
      "error 2675.385498046875\n",
      "5 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.62\n",
      "error 83.38909912109375\n",
      "5 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 10577.3173828125\n",
      "5 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.19\n",
      "error 92.07219696044922\n",
      "6 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.38\n",
      "error 2477.30419921875\n",
      "6 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.62\n",
      "error 89.72206115722656\n",
      "6 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 9771.173828125\n",
      "6 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.13\n",
      "error 124.53684997558594\n",
      "7 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.38\n",
      "error 3564.370849609375\n",
      "7 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 86.3302993774414\n",
      "7 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 10633.72265625\n",
      "7 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.16\n",
      "error 126.62216186523438\n",
      "8 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.39\n",
      "error 4131.41455078125\n",
      "8 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 126.92552947998047\n",
      "8 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 10146.5859375\n",
      "8 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.21\n",
      "error 155.422119140625\n",
      "9 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.39\n",
      "error 5206.77880859375\n",
      "9 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 164.68972778320312\n",
      "9 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 9967.771484375\n",
      "9 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.14\n",
      "error 170.19467163085938\n",
      "10 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.39\n",
      "error 5972.3984375\n",
      "10 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 174.927734375\n",
      "10 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 9478.314453125\n",
      "10 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.15\n",
      "error 187.3141632080078\n",
      "11 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.41\n",
      "error 6875.8486328125\n",
      "11 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 350.43011474609375\n",
      "11 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 9027.76171875\n",
      "11 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.18\n",
      "error 201.07379150390625\n",
      "12 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 6371.341796875\n",
      "12 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 260.6058349609375\n",
      "12 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 9483.009765625\n",
      "12 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.17\n",
      "error 226.70062255859375\n",
      "13 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.41\n",
      "error 7949.87158203125\n",
      "13 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 287.59710693359375\n",
      "13 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 9400.82421875\n",
      "13 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.26\n",
      "error 258.4915466308594\n",
      "14 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.41\n",
      "error 8882.9697265625\n",
      "14 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 292.6747741699219\n",
      "14 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 9974.4794921875\n",
      "14 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.19\n",
      "error 257.9419860839844\n",
      "15 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.41\n",
      "error 10191.6474609375\n",
      "15 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 348.10546875\n",
      "15 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 10087.05078125\n",
      "15 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.25\n",
      "error 254.16317749023438\n",
      "16 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 11702.201171875\n",
      "16 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 346.7781982421875\n",
      "16 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 10274.1103515625\n",
      "16 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.19\n",
      "error 247.01502990722656\n",
      "17 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 11614.453125\n",
      "17 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 353.6601257324219\n",
      "17 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 10707.361328125\n",
      "17 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.20\n",
      "error 250.61341857910156\n",
      "18 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.39\n",
      "error 10142.822265625\n",
      "18 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 282.1038818359375\n",
      "18 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 11575.6357421875\n",
      "18 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.30\n",
      "error 255.10302734375\n",
      "19 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 11655.36328125\n",
      "19 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 273.7667236328125\n",
      "19 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 12500.556640625\n",
      "19 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.20\n",
      "error 268.74114990234375\n",
      "20 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.41\n",
      "error 12037.330078125\n",
      "20 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 278.042236328125\n",
      "20 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 13935.30859375\n",
      "20 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.20\n",
      "error 282.6186828613281\n",
      "21 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 12375.837890625\n",
      "21 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 275.3954772949219\n",
      "21 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 15060.9951171875\n",
      "21 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.21\n",
      "error 283.67840576171875\n",
      "22 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 11598.642578125\n",
      "22 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 213.49993896484375\n",
      "22 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 15884.5185546875\n",
      "22 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.20\n",
      "error 292.3230285644531\n",
      "23 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 12663.7958984375\n",
      "23 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 207.34286499023438\n",
      "23 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 16921.34765625\n",
      "23 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.21\n",
      "error 314.57818603515625\n",
      "24 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 12746.47265625\n",
      "24 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 247.91465759277344\n",
      "24 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 18076.44140625\n",
      "24 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.20\n",
      "error 315.8557434082031\n",
      "25 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 13114.31640625\n",
      "25 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 230.86358642578125\n",
      "25 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 19241.953125\n",
      "25 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.19\n",
      "error 332.0620422363281\n",
      "26 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 12857.9365234375\n",
      "26 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 228.7596893310547\n",
      "26 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 20112.20703125\n",
      "26 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.19\n",
      "error 360.31451416015625\n",
      "27 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.39\n",
      "error 13345.29296875\n",
      "27 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 301.9107666015625\n",
      "27 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 20797.279296875\n",
      "27 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.21\n",
      "error 417.1062316894531\n",
      "28 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.38\n",
      "error 14731.28515625\n",
      "28 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 440.28106689453125\n",
      "28 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 20284.41796875\n",
      "28 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.15\n",
      "error 529.7552490234375\n",
      "29 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 14368.10546875\n",
      "29 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 366.4473571777344\n",
      "29 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 18792.76171875\n",
      "29 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.16\n",
      "error 729.8279418945312\n",
      "30 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.41\n",
      "error 12088.884765625\n",
      "30 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 441.53466796875\n",
      "30 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 13230.681640625\n",
      "30 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.18\n",
      "error 724.875732421875\n",
      "31 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.43\n",
      "error 455.68243408203125\n",
      "31 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 90.8716812133789\n",
      "31 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 802.5172119140625\n",
      "31 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.18\n",
      "error 34.84049987792969\n"
     ]
    }
   ],
   "source": [
    "mpt_sequential(mpt, train_dataloader, MAX_SEQ_LEN, \"cuda\", sparsegpt_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path_to_save = \"./run-0-50sparse\"\n",
    "os.makedirs(path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying adapt_tokenizer.py...\n",
      "Copying attention.py...\n",
      "Copying blocks.py...\n",
      "Copying config.json...\n",
      "Copying configuration_mpt.py...\n",
      "Copying custom_embedding.py...\n",
      "Copying flash_attn_triton.py...\n",
      "Copying generation_config.json...\n",
      "Copying hf_prefixlm_converter.py...\n",
      "Copying meta_init_context.py...\n",
      "Copying modeling_mpt.py...\n",
      "Copying norm.py...\n",
      "Copying param_init_fns.py...\n",
      "Copying special_tokens_map.json...\n",
      "Copying tokenizer.json...\n",
      "Copying tokenizer_config.json...\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "files_to_copy = [\n",
    "    \"adapt_tokenizer.py\",\n",
    "    \"attention.py\",\n",
    "    \"blocks.py\",\n",
    "    \"config.json\",\n",
    "    \"configuration_mpt.py\",\n",
    "    \"custom_embedding.py\",\n",
    "    \"flash_attn_triton.py\",\n",
    "    \"generation_config.json\",\n",
    "    \"hf_prefixlm_converter.py\",\n",
    "    \"meta_init_context.py\",\n",
    "    \"modeling_mpt.py\",\n",
    "    \"norm.py\",\n",
    "    \"param_init_fns.py\",\n",
    "    \"special_tokens_map.json\",\n",
    "    \"tokenizer.json\",\n",
    "    \"tokenizer_config.json\",\n",
    "]\n",
    "\n",
    "for f in files_to_copy:\n",
    "    print(f\"Copying {f}...\")\n",
    "    shutil.copyfile(os.path.join(model_path, f), os.path.join(path_to_save, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpt.save_pretrained(path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload Model and Confirm Its Running Nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- HERE: INITIALIZE MODEL -----\n",
      "You are using config.init_device='cpu', but you can also use config.init_device=\"meta\" with Composer + FSDP for fast initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f01b55130c84075be4d3c4ab8b6f3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "mpt2 = AutoModelForCausalLM.from_pretrained(path_to_save, trust_remote_code=True)\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?Weng earned $12/hour * 50 minutes = $<<12*50=600>>600.\n",
      "#### 600<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\"\n",
    "inputs = tokenizer2(prompt, return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = mpt2.generate(**inputs, max_new_tokens=50, eos_token_id=tokenizer2.eos_token_id)\n",
    "print(tokenizer2.batch_decode(generated_ids)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity distribution:\n",
      "transformer.wte.weight = 0.00 %\n",
      "transformer.blocks.0.norm_1.weight = 0.00 %\n",
      "transformer.blocks.0.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.0.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.0.norm_2.weight = 0.00 %\n",
      "transformer.blocks.0.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.0.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.1.norm_1.weight = 0.00 %\n",
      "transformer.blocks.1.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.1.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.1.norm_2.weight = 0.00 %\n",
      "transformer.blocks.1.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.1.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.2.norm_1.weight = 0.00 %\n",
      "transformer.blocks.2.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.2.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.2.norm_2.weight = 0.00 %\n",
      "transformer.blocks.2.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.2.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.3.norm_1.weight = 0.00 %\n",
      "transformer.blocks.3.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.3.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.3.norm_2.weight = 0.00 %\n",
      "transformer.blocks.3.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.3.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.4.norm_1.weight = 0.00 %\n",
      "transformer.blocks.4.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.4.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.4.norm_2.weight = 0.00 %\n",
      "transformer.blocks.4.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.4.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.5.norm_1.weight = 0.00 %\n",
      "transformer.blocks.5.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.5.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.5.norm_2.weight = 0.00 %\n",
      "transformer.blocks.5.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.5.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.6.norm_1.weight = 0.00 %\n",
      "transformer.blocks.6.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.6.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.6.norm_2.weight = 0.00 %\n",
      "transformer.blocks.6.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.6.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.7.norm_1.weight = 0.00 %\n",
      "transformer.blocks.7.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.7.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.7.norm_2.weight = 0.00 %\n",
      "transformer.blocks.7.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.7.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.8.norm_1.weight = 0.00 %\n",
      "transformer.blocks.8.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.8.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.8.norm_2.weight = 0.00 %\n",
      "transformer.blocks.8.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.8.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.9.norm_1.weight = 0.00 %\n",
      "transformer.blocks.9.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.9.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.9.norm_2.weight = 0.00 %\n",
      "transformer.blocks.9.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.9.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.10.norm_1.weight = 0.00 %\n",
      "transformer.blocks.10.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.10.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.10.norm_2.weight = 0.00 %\n",
      "transformer.blocks.10.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.10.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.11.norm_1.weight = 0.00 %\n",
      "transformer.blocks.11.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.11.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.11.norm_2.weight = 0.00 %\n",
      "transformer.blocks.11.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.11.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.12.norm_1.weight = 0.00 %\n",
      "transformer.blocks.12.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.12.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.12.norm_2.weight = 0.00 %\n",
      "transformer.blocks.12.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.12.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.13.norm_1.weight = 0.00 %\n",
      "transformer.blocks.13.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.13.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.13.norm_2.weight = 0.00 %\n",
      "transformer.blocks.13.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.13.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.14.norm_1.weight = 0.00 %\n",
      "transformer.blocks.14.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.14.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.14.norm_2.weight = 0.00 %\n",
      "transformer.blocks.14.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.14.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.15.norm_1.weight = 0.00 %\n",
      "transformer.blocks.15.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.15.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.15.norm_2.weight = 0.00 %\n",
      "transformer.blocks.15.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.15.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.16.norm_1.weight = 0.00 %\n",
      "transformer.blocks.16.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.16.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.16.norm_2.weight = 0.00 %\n",
      "transformer.blocks.16.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.16.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.17.norm_1.weight = 0.00 %\n",
      "transformer.blocks.17.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.17.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.17.norm_2.weight = 0.00 %\n",
      "transformer.blocks.17.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.17.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.18.norm_1.weight = 0.00 %\n",
      "transformer.blocks.18.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.18.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.18.norm_2.weight = 0.00 %\n",
      "transformer.blocks.18.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.18.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.19.norm_1.weight = 0.00 %\n",
      "transformer.blocks.19.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.19.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.19.norm_2.weight = 0.00 %\n",
      "transformer.blocks.19.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.19.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.20.norm_1.weight = 0.00 %\n",
      "transformer.blocks.20.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.20.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.20.norm_2.weight = 0.00 %\n",
      "transformer.blocks.20.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.20.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.21.norm_1.weight = 0.00 %\n",
      "transformer.blocks.21.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.21.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.21.norm_2.weight = 0.00 %\n",
      "transformer.blocks.21.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.21.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.22.norm_1.weight = 0.00 %\n",
      "transformer.blocks.22.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.22.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.22.norm_2.weight = 0.00 %\n",
      "transformer.blocks.22.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.22.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.23.norm_1.weight = 0.00 %\n",
      "transformer.blocks.23.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.23.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.23.norm_2.weight = 0.00 %\n",
      "transformer.blocks.23.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.23.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.24.norm_1.weight = 0.00 %\n",
      "transformer.blocks.24.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.24.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.24.norm_2.weight = 0.00 %\n",
      "transformer.blocks.24.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.24.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.25.norm_1.weight = 0.00 %\n",
      "transformer.blocks.25.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.25.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.25.norm_2.weight = 0.00 %\n",
      "transformer.blocks.25.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.25.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.26.norm_1.weight = 0.00 %\n",
      "transformer.blocks.26.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.26.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.26.norm_2.weight = 0.00 %\n",
      "transformer.blocks.26.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.26.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.27.norm_1.weight = 0.00 %\n",
      "transformer.blocks.27.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.27.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.27.norm_2.weight = 0.00 %\n",
      "transformer.blocks.27.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.27.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.28.norm_1.weight = 0.00 %\n",
      "transformer.blocks.28.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.28.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.28.norm_2.weight = 0.00 %\n",
      "transformer.blocks.28.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.28.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.29.norm_1.weight = 0.00 %\n",
      "transformer.blocks.29.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.29.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.29.norm_2.weight = 0.00 %\n",
      "transformer.blocks.29.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.29.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.30.norm_1.weight = 0.00 %\n",
      "transformer.blocks.30.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.30.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.30.norm_2.weight = 0.00 %\n",
      "transformer.blocks.30.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.30.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.31.norm_1.weight = 0.00 %\n",
      "transformer.blocks.31.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.31.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.31.norm_2.weight = 0.00 %\n",
      "transformer.blocks.31.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.31.ffn.down_proj.weight = 50.00 %\n",
      "transformer.norm_f.weight = 0.00 %\n",
      "lm_head.weight = 0.00 %\n"
     ]
    }
   ],
   "source": [
    "print_sparsity(mpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc == 0.235"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
