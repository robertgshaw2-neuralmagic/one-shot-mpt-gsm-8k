{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = \"./mpt-gsm8k-dense/training\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- HERE: INITIALIZE MODEL -----\n",
      "You are using config.init_device='cpu', but you can also use config.init_device=\"meta\" with Composer + FSDP for fast initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59aee510998f432eaf6929cb86c7bce7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "mpt = AutoModelForCausalLM.from_pretrained(model_path, trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mpt.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/transformers/generation/utils.py:1417: UserWarning: You have modified the pretrained model configuration to control generation. This is a deprecated strategy to control generation and will be removed soon, in a future version. Please use a generation configuration file (see https://huggingface.co/docs/transformers/main_classes/text_generation )\n",
      "  warnings.warn(\n",
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?Weng earns $12/hour * 50 minutes = $<<12*50=600>>600 for babysitting.\n",
      "#### 600<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = mpt.generate(**inputs, max_new_tokens=50, eos_token_id=tokenizer.eos_token_id)\n",
    "print(tokenizer.batch_decode(generated_ids)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "experiments.ipynb\t quant_linearW8A8MatMul8Embeds8LMhead8.yaml\n",
      "experiments-quant.ipynb  run-0-50sparse\n",
      "llm-foundry\t\t run-0-50sparse-results\n",
      "lm-evaluation-harness\t run-0-50sparse.tar.gz\n",
      "mpt-gsm8k-dense\t\t sparseml\n",
      "neuralmagicml\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmagicml.research.sparsegpt.modelutils import (\n",
    "    apply_recipe, \n",
    "    initialize_scales_from_batches, \n",
    "    find_quant_layers, \n",
    "    find_layers, \n",
    "    freeze_bn_stats\n",
    ")\n",
    "\n",
    "class SparseGPTConfig:\n",
    "    def __init__(\n",
    "        self,\n",
    "        nsamples=128,\n",
    "        sparsity=0.5,\n",
    "        minlayer=-1,\n",
    "        maxlayer=100,\n",
    "        prune_only = \"\",\n",
    "        invert=False,\n",
    "        prune_n=0,\n",
    "        prune_m=0,\n",
    "        perc_damp=0.01,\n",
    "        blocksize=128,\n",
    "        ptq=False,\n",
    "        quantize_attn_matmuls=False,\n",
    "        quantize_embeddings_and_lmhead=False,\n",
    "        recipe=\"\",\n",
    "        observer_batches=100\n",
    "    ):\n",
    "        self.nsamples = nsamples\n",
    "        self.sparsity = sparsity\n",
    "        self.minlayer = minlayer\n",
    "        self.maxlayer = maxlayer\n",
    "        self.prune_only = prune_only\n",
    "        self.invert = invert\n",
    "        self.prune_n = prune_n\n",
    "        self.prune_m = prune_m\n",
    "        self.perc_damp = perc_damp\n",
    "        self.blocksize = blocksize\n",
    "        self.ptq = ptq\n",
    "        self.quantize_attn_matmuls = quantize_attn_matmuls\n",
    "        self.quantize_embeddings_and_lmhead = quantize_embeddings_and_lmhead\n",
    "        self.recipe = recipe\n",
    "        self.observer_batches = observer_batches\n",
    "\n",
    "sparsegpt_config = SparseGPTConfig(\n",
    "    ptq=True,\n",
    "    quantize_attn_matmuls=True,\n",
    "    quantize_embeddings_and_lmhead=True,\n",
    "    recipe=\"quant_linearW8A8MatMul8Embeds8LMhead8.yaml\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'answer'],\n",
       "    num_rows: 7473\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"gsm8k\", \"main\")\n",
    "train_dataset = dataset[\"train\"]\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForLanguageModeling\n",
    "from datasets import load_dataset\n",
    "\n",
    "BATCH_SIZE = 1\n",
    "MAX_SEQ_LEN = 512\n",
    "\n",
    "def tokenize_fn(element):\n",
    "    text = f'{element[\"question\"]} {element[\"answer\"]}'\n",
    "\n",
    "    outputs = tokenizer(\n",
    "        text,\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_SEQ_LEN,\n",
    "        return_overflowing_tokens=False,\n",
    "        return_length=False,\n",
    "    )\n",
    "    return {\n",
    "        \"input_ids\": outputs[\"input_ids\"],\n",
    "        \"attention_mask\": outputs[\"attention_mask\"]\n",
    "    }\n",
    "\n",
    "tokenized_dataset_train = train_dataset.map(\n",
    "    tokenize_fn,\n",
    "    batched=False,\n",
    "    remove_columns=train_dataset.column_names,\n",
    "    batch_size=BATCH_SIZE,\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False)\n",
    "train_dataloader = torch.utils.data.DataLoader(\n",
    "    tokenized_dataset_train, \n",
    "    shuffle=True, \n",
    "    collate_fn=data_collator, \n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run SparseGPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-10-24 13:35:59 sparseml.pytorch.utils.logger INFO     Logging all SparseML modifier-level logs to sparse_logs/24-10-2023_13.35.59.log\n"
     ]
    }
   ],
   "source": [
    "model, manager = apply_recipe(mpt, sparsegpt_config.recipe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting data statistics for quantization scales...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800000; text-decoration-color: #800000\">╭─────────────────────────────── </span><span style=\"color: #800000; text-decoration-color: #800000; font-weight: bold\">Traceback </span><span style=\"color: #bf7f7f; text-decoration-color: #bf7f7f; font-weight: bold\">(most recent call last)</span><span style=\"color: #800000; text-decoration-color: #800000\"> ────────────────────────────────╮</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">&lt;module&gt;</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">1</span>                                                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>1 initialize_scales_from_batches(model, train_dataloader, sparsegpt_config.observer_batche     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2 </span>                                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/rshaw/llm-sparsegpt-mpt-gsm/neuralmagicml/research/sparsegpt/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modelutils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">52</span> in           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">initialize_scales_from_batches</span>                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">49 </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">initialize_scales_from_batches</span>(model, data_loader, num_batches):                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">50 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">print</span>(<span style=\"color: #808000; text-decoration-color: #808000\">\"Collecting data statistics for quantization scales...\"</span>)                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">51 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>model.eval()                                                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>52 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>model.to(DEV)                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">53 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                                   <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">54 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>batches = <span style=\"color: #0000ff; text-decoration-color: #0000ff\">0</span>                                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">55 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">while</span> batches &lt; num_batches:                                                        <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/transformers/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">modeling_utils.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">205</span> <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">8</span> in <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2055 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #808000; text-decoration-color: #808000\">\" model has already been set to the correct devices and casted to the co</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2056 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>)                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2057 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span>:                                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span>2058 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">super</span>().to(*args, **kwargs)                                            <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2059 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2060 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">half</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, *args):                                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">2061 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># Checks if the model is quantized</span>                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">989</span> in  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">to</span>                                                                                               <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 986 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>non_blocking, memory_format=convert_to_format)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 987 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">No</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 988 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 989 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._apply(convert)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 990 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 991 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">register_backward_hook</span>(                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 992 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, hook: Callable[[<span style=\"color: #808000; text-decoration-color: #808000\">'Module'</span>, _grad_t, _grad_t], Union[<span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span>, Tensor]]           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">641</span> in  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 638 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 639 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 640 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 641 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">641</span> in  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 638 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 639 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 640 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 641 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">641</span> in  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 638 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 639 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 640 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 641 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">641</span> in  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 638 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 639 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 640 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 641 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">641</span> in  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 638 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 639 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 640 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 641 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">641</span> in  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 638 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span>                                                                                      <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 639 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>(<span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>, fn):                                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 640 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">for</span> module <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>.children():                                                    <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 641 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>module._apply(fn)                                                             <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 642 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 643 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">def</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">compute_should_use_set_data</span>(tensor, tensor_applied):                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 644 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">664</span> in  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">_apply</span>                                                                                           <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 661 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># track autograd history of `param_applied`, so we have to use</span>                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 662 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"># `with torch.no_grad():`</span>                                                     <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 663 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">with</span> torch.no_grad():                                                         <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 664 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>param_applied = fn(param)                                                 <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 665 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span>should_use_set_data = compute_should_use_set_data(param, param_applied)       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 666 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> should_use_set_data:                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 667 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span>param.data = param_applied                                                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #bfbf7f; text-decoration-color: #bfbf7f\">/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/</span><span style=\"color: #808000; text-decoration-color: #808000; font-weight: bold\">module.py</span>:<span style=\"color: #0000ff; text-decoration-color: #0000ff\">987</span> in  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #00ff00; text-decoration-color: #00ff00\">convert</span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>                                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 984 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> convert_to_format <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">is</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">not</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">None</span> <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">and</span> t.dim() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">in</span> (<span style=\"color: #0000ff; text-decoration-color: #0000ff\">4</span>, <span style=\"color: #0000ff; text-decoration-color: #0000ff\">5</span>):                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 985 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">els</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 986 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   │   │   │   │   </span>non_blocking, memory_format=convert_to_format)                <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span> <span style=\"color: #800000; text-decoration-color: #800000\">❱ </span> 987 <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> t.to(device, dtype <span style=\"color: #0000ff; text-decoration-color: #0000ff\">if</span> t.is_floating_point() <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">or</span> t.is_complex() <span style=\"color: #0000ff; text-decoration-color: #0000ff\">else</span> <span style=\"color: #0000ff; text-decoration-color: #0000ff\">No</span>  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 988 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span>                                                                                  <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 989 </span><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">│   │   </span><span style=\"color: #0000ff; text-decoration-color: #0000ff\">return</span> <span style=\"color: #00ffff; text-decoration-color: #00ffff\">self</span>._apply(convert)                                                       <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">│</span>   <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 990 </span>                                                                                          <span style=\"color: #800000; text-decoration-color: #800000\">│</span>\n",
       "<span style=\"color: #800000; text-decoration-color: #800000\">╰──────────────────────────────────────────────────────────────────────────────────────────────────╯</span>\n",
       "<span style=\"color: #ff0000; text-decoration-color: #ff0000; font-weight: bold\">OutOfMemoryError: </span>CUDA out of memory. Tried to allocate <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">192.00</span> MiB <span style=\"font-weight: bold\">(</span>GPU <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.74</span> GiB total capacity; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.02</span> GiB \n",
       "already allocated; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">80.19</span> MiB free; <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">15.02</span> GiB reserved in total by PyTorch<span style=\"font-weight: bold\">)</span> If reserved memory is &gt;&gt; allocated \n",
       "memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[31m╭─\u001b[0m\u001b[31m──────────────────────────────\u001b[0m\u001b[31m \u001b[0m\u001b[1;31mTraceback \u001b[0m\u001b[1;2;31m(most recent call last)\u001b[0m\u001b[31m \u001b[0m\u001b[31m───────────────────────────────\u001b[0m\u001b[31m─╮\u001b[0m\n",
       "\u001b[31m│\u001b[0m in \u001b[92m<module>\u001b[0m:\u001b[94m1\u001b[0m                                                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m1 initialize_scales_from_batches(model, train_dataloader, sparsegpt_config.observer_batche     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2 \u001b[0m                                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/rshaw/llm-sparsegpt-mpt-gsm/neuralmagicml/research/sparsegpt/\u001b[0m\u001b[1;33mmodelutils.py\u001b[0m:\u001b[94m52\u001b[0m in           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92minitialize_scales_from_batches\u001b[0m                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m49 \u001b[0m\u001b[94mdef\u001b[0m \u001b[92minitialize_scales_from_batches\u001b[0m(model, data_loader, num_batches):                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m50 \u001b[0m\u001b[2m│   \u001b[0m\u001b[96mprint\u001b[0m(\u001b[33m\"\u001b[0m\u001b[33mCollecting data statistics for quantization scales...\u001b[0m\u001b[33m\"\u001b[0m)                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m51 \u001b[0m\u001b[2m│   \u001b[0mmodel.eval()                                                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m52 \u001b[2m│   \u001b[0mmodel.to(DEV)                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m53 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                                   \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m54 \u001b[0m\u001b[2m│   │   \u001b[0mbatches = \u001b[94m0\u001b[0m                                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m55 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mwhile\u001b[0m batches < num_batches:                                                        \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/transformers/\u001b[0m\u001b[1;33mmodeling_utils.py\u001b[0m:\u001b[94m205\u001b[0m \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[94m8\u001b[0m in \u001b[92mto\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2055 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[33m\"\u001b[0m\u001b[33m model has already been set to the correct devices and casted to the co\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2056 \u001b[0m\u001b[2m│   │   │   \u001b[0m)                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2057 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94melse\u001b[0m:                                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m2058 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96msuper\u001b[0m().to(*args, **kwargs)                                            \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2059 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2060 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mhalf\u001b[0m(\u001b[96mself\u001b[0m, *args):                                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m2061 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[2m# Checks if the model is quantized\u001b[0m                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m989\u001b[0m in  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mto\u001b[0m                                                                                               \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 986 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mnon_blocking, memory_format=convert_to_format)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 987 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m t.to(device, dtype \u001b[94mif\u001b[0m t.is_floating_point() \u001b[95mor\u001b[0m t.is_complex() \u001b[94melse\u001b[0m \u001b[94mNo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 988 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 989 \u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._apply(convert)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 990 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 991 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mregister_backward_hook\u001b[0m(                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 992 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[96mself\u001b[0m, hook: Callable[[\u001b[33m'\u001b[0m\u001b[33mModule\u001b[0m\u001b[33m'\u001b[0m, _grad_t, _grad_t], Union[\u001b[94mNone\u001b[0m, Tensor]]           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m641\u001b[0m in  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_apply\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 638 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 639 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 640 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 641 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 642 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 643 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 644 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m641\u001b[0m in  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_apply\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 638 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 639 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 640 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 641 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 642 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 643 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 644 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m641\u001b[0m in  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_apply\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 638 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 639 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 640 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 641 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 642 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 643 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 644 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m641\u001b[0m in  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_apply\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 638 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 639 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 640 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 641 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 642 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 643 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 644 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m641\u001b[0m in  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_apply\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 638 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 639 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 640 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 641 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 642 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 643 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 644 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m641\u001b[0m in  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_apply\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 638 \u001b[0m\u001b[2m│   \u001b[0m                                                                                      \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 639 \u001b[0m\u001b[2m│   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92m_apply\u001b[0m(\u001b[96mself\u001b[0m, fn):                                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 640 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mfor\u001b[0m module \u001b[95min\u001b[0m \u001b[96mself\u001b[0m.children():                                                    \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 641 \u001b[2m│   │   │   \u001b[0mmodule._apply(fn)                                                             \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 642 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 643 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mdef\u001b[0m \u001b[92mcompute_should_use_set_data\u001b[0m(tensor, tensor_applied):                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 644 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m torch._has_compatible_shallow_copy_type(tensor, tensor_applied):           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m664\u001b[0m in  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92m_apply\u001b[0m                                                                                           \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 661 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# track autograd history of `param_applied`, so we have to use\u001b[0m                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 662 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[2m# `with torch.no_grad():`\u001b[0m                                                     \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 663 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mwith\u001b[0m torch.no_grad():                                                         \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 664 \u001b[2m│   │   │   │   \u001b[0mparam_applied = fn(param)                                                 \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 665 \u001b[0m\u001b[2m│   │   │   \u001b[0mshould_use_set_data = compute_should_use_set_data(param, param_applied)       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 666 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m should_use_set_data:                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 667 \u001b[0m\u001b[2m│   │   │   │   \u001b[0mparam.data = param_applied                                                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[2;33m/home/rshaw/.conda/envs/sparsegpt/lib/python3.9/site-packages/torch/nn/modules/\u001b[0m\u001b[1;33mmodule.py\u001b[0m:\u001b[94m987\u001b[0m in  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[92mconvert\u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m                                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 984 \u001b[0m\u001b[2m│   │   │   \u001b[0m\u001b[94mif\u001b[0m convert_to_format \u001b[95mis\u001b[0m \u001b[95mnot\u001b[0m \u001b[94mNone\u001b[0m \u001b[95mand\u001b[0m t.dim() \u001b[95min\u001b[0m (\u001b[94m4\u001b[0m, \u001b[94m5\u001b[0m):                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 985 \u001b[0m\u001b[2m│   │   │   │   \u001b[0m\u001b[94mreturn\u001b[0m t.to(device, dtype \u001b[94mif\u001b[0m t.is_floating_point() \u001b[95mor\u001b[0m t.is_complex() \u001b[94mels\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 986 \u001b[0m\u001b[2m│   │   │   │   │   │   │   \u001b[0mnon_blocking, memory_format=convert_to_format)                \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m \u001b[31m❱ \u001b[0m 987 \u001b[2m│   │   │   \u001b[0m\u001b[94mreturn\u001b[0m t.to(device, dtype \u001b[94mif\u001b[0m t.is_floating_point() \u001b[95mor\u001b[0m t.is_complex() \u001b[94melse\u001b[0m \u001b[94mNo\u001b[0m  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 988 \u001b[0m\u001b[2m│   │   \u001b[0m                                                                                  \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 989 \u001b[0m\u001b[2m│   │   \u001b[0m\u001b[94mreturn\u001b[0m \u001b[96mself\u001b[0m._apply(convert)                                                       \u001b[31m│\u001b[0m\n",
       "\u001b[31m│\u001b[0m   \u001b[2m 990 \u001b[0m                                                                                          \u001b[31m│\u001b[0m\n",
       "\u001b[31m╰──────────────────────────────────────────────────────────────────────────────────────────────────╯\u001b[0m\n",
       "\u001b[1;91mOutOfMemoryError: \u001b[0mCUDA out of memory. Tried to allocate \u001b[1;36m192.00\u001b[0m MiB \u001b[1m(\u001b[0mGPU \u001b[1;36m0\u001b[0m; \u001b[1;36m15.74\u001b[0m GiB total capacity; \u001b[1;36m15.02\u001b[0m GiB \n",
       "already allocated; \u001b[1;36m80.19\u001b[0m MiB free; \u001b[1;36m15.02\u001b[0m GiB reserved in total by PyTorch\u001b[1m)\u001b[0m If reserved memory is >> allocated \n",
       "memory try setting max_split_size_mb to avoid fragmentation.  See documentation for Memory Management and \n",
       "PYTORCH_CUDA_ALLOC_CONF\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "initialize_scales_from_batches(model, train_dataloader, sparsegpt_config.observer_batches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from neuralmagicml.research.sparsegpt.sparsegpt import SparseGPT\n",
    "from neuralmagicml.research.sparsegpt.quant import WeightFakeQuantizer\n",
    "\n",
    "@torch.no_grad()\n",
    "def mpt_sequential(model, dataloader, data_seq_len, dev, cfg):\n",
    "    assert cfg.nsamples > 0, \"When using sparsegpt, nsamples must be > 0\"\n",
    "    NSAMPLES = cfg.nsamples\n",
    "    SPARSITY = cfg.sparsity\n",
    "    MINLAYER = cfg.minlayer\n",
    "    MAXLAYER = cfg.maxlayer\n",
    "    PRUNE_ONLY = cfg.prune_only\n",
    "    INVERT = cfg.invert\n",
    "    PRUNE_N = cfg.prune_n\n",
    "    PRUNE_M = cfg.prune_m\n",
    "    PERC_DAMP = cfg.perc_damp\n",
    "    BLOCKSIZE = cfg.blocksize\n",
    "\n",
    "    PTQ = cfg.ptq\n",
    "    print(f\"PTQ = {PTQ}\")\n",
    "    if PTQ:\n",
    "        model, manager = apply_recipe(model, cfg.recipe)\n",
    "        initialize_scales_from_batches(model, dataloader, cfg.observer_batches)\n",
    "\n",
    "    print(\"Starting ...\")\n",
    "\n",
    "    use_cache = model.config.use_cache\n",
    "    model.config.use_cache = False\n",
    "    layers = model.transformer.blocks\n",
    "\n",
    "    model.transformer.wte = model.transformer.wte.to(dev)\n",
    "    layers[0] = layers[0].to(dev)\n",
    "\n",
    "    dtype = next(iter(model.parameters())).dtype\n",
    "    inps = torch.zeros(\n",
    "        (NSAMPLES, data_seq_len, model.config.d_model), dtype=dtype, device=dev\n",
    "    )\n",
    "    cache = []\n",
    "    # cache_attn_mask = []\n",
    "\n",
    "    class Catcher(torch.nn.Module):\n",
    "        def __init__(self, module):\n",
    "            super().__init__()\n",
    "            self.module = module\n",
    "\n",
    "        def forward(self, inp, **kwargs):\n",
    "            inps[len(cache)] = inp\n",
    "            cache.append(kwargs[\"attn_bias\"])\n",
    "            raise ValueError\n",
    "\n",
    "    layers[0] = Catcher(layers[0])\n",
    "    i = 0\n",
    "    \n",
    "    for batch in iter(dataloader):\n",
    "        try:\n",
    "            tmp = {k: v.to(dev) for k, v in batch.items()}\n",
    "            # cache_attn_mask.append(tmp[\"attention_mask\"])\n",
    "            model(**tmp)\n",
    "        except ValueError:\n",
    "            pass\n",
    "        i += 1\n",
    "        if i == NSAMPLES:\n",
    "            break\n",
    "    layers[0] = layers[0].module\n",
    "\n",
    "    layers[0] = layers[0].cpu()\n",
    "    model.transformer.wte = model.transformer.wte.cpu()\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    outs = torch.zeros_like(inps)\n",
    "\n",
    "    print(\"Ready.\")\n",
    "\n",
    "    for i in range(len(layers)):\n",
    "        layer = layers[i].to(dev)\n",
    "        if PTQ:\n",
    "            # The layer names are changed due to quantization modifiers, therefore\n",
    "            # we need a slightly different func to retrieve layers\n",
    "            subset = find_quant_layers(layer)\n",
    "        else:\n",
    "            subset = find_layers(layer)\n",
    "\n",
    "        gpts = {}\n",
    "        for name in subset:\n",
    "            if (not (MINLAYER <= i < MAXLAYER and PRUNE_ONLY in name)) == (not INVERT):\n",
    "                continue\n",
    "            gpts[name] = SparseGPT(subset[name])\n",
    "            if PTQ:\n",
    "                gpts[name].quantizer = WeightFakeQuantizer(subset[name])\n",
    "\n",
    "        def add_batch(name):\n",
    "            def tmp(_, inp, out):\n",
    "                gpts[name].add_batch(inp[0].data, out.data)\n",
    "\n",
    "            return tmp\n",
    "\n",
    "        handles = []\n",
    "        for name in gpts:\n",
    "            handles.append(subset[name].register_forward_hook(add_batch(name)))\n",
    "        \n",
    "        for j in range(NSAMPLES):\n",
    "            outs[j] = layer(inps[j].unsqueeze(0), attn_bias=cache[j])[0]\n",
    "        for h in handles:\n",
    "            h.remove()\n",
    "\n",
    "        for name in gpts:\n",
    "            print(i, name)\n",
    "            print(\"Pruning ...\")\n",
    "            gpts[name].fasterprune(\n",
    "                SPARSITY,\n",
    "                prunen=PRUNE_N,\n",
    "                prunem=PRUNE_M,\n",
    "                percdamp=PERC_DAMP,\n",
    "                blocksize=BLOCKSIZE,\n",
    "            )\n",
    "            gpts[name].free()\n",
    "\n",
    "        for j in range(NSAMPLES):\n",
    "            outs[j] = layer(inps[j].unsqueeze(0), attn_bias=cache[j])[0]\n",
    "\n",
    "        layers[i] = layer.cpu()\n",
    "        del layer\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "        inps, outs = outs, inps\n",
    "\n",
    "    print(model)\n",
    "    model.apply(torch.quantization.disable_observer)\n",
    "    model.apply(freeze_bn_stats)\n",
    "    model.config.use_cache = use_cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PTQ = False\n",
      "Starting ...\n",
      "Ready.\n",
      "0 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.91\n",
      "error 25.434906005859375\n",
      "0 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 18.28067398071289\n",
      "0 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 4068.03173828125\n",
      "0 ffn.down_proj\n",
      "Pruning ...\n",
      "time 3.98\n",
      "error 12.001224517822266\n",
      "1 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.30\n",
      "error 232.1502685546875\n",
      "1 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 10.658576965332031\n",
      "1 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 5781.634765625\n",
      "1 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.07\n",
      "error 12.84139347076416\n",
      "2 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.35\n",
      "error 394.74127197265625\n",
      "2 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 52.782859802246094\n",
      "2 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 6154.84033203125\n",
      "2 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.06\n",
      "error 61.63454818725586\n",
      "3 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.35\n",
      "error 772.435546875\n",
      "3 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 19.284317016601562\n",
      "3 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 9611.99609375\n",
      "3 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.12\n",
      "error 41.04884719848633\n",
      "4 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.37\n",
      "error 1467.7095947265625\n",
      "4 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 38.02000427246094\n",
      "4 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 10461.02734375\n",
      "4 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.13\n",
      "error 60.27094268798828\n",
      "5 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.38\n",
      "error 2675.385498046875\n",
      "5 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.62\n",
      "error 83.38909912109375\n",
      "5 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 10577.3173828125\n",
      "5 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.19\n",
      "error 92.07219696044922\n",
      "6 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.38\n",
      "error 2477.30419921875\n",
      "6 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.62\n",
      "error 89.72206115722656\n",
      "6 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 9771.173828125\n",
      "6 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.13\n",
      "error 124.53684997558594\n",
      "7 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.38\n",
      "error 3564.370849609375\n",
      "7 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 86.3302993774414\n",
      "7 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 10633.72265625\n",
      "7 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.16\n",
      "error 126.62216186523438\n",
      "8 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.39\n",
      "error 4131.41455078125\n",
      "8 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 126.92552947998047\n",
      "8 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 10146.5859375\n",
      "8 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.21\n",
      "error 155.422119140625\n",
      "9 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.39\n",
      "error 5206.77880859375\n",
      "9 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 164.68972778320312\n",
      "9 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 9967.771484375\n",
      "9 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.14\n",
      "error 170.19467163085938\n",
      "10 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.39\n",
      "error 5972.3984375\n",
      "10 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 174.927734375\n",
      "10 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 9478.314453125\n",
      "10 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.15\n",
      "error 187.3141632080078\n",
      "11 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.41\n",
      "error 6875.8486328125\n",
      "11 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 350.43011474609375\n",
      "11 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 9027.76171875\n",
      "11 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.18\n",
      "error 201.07379150390625\n",
      "12 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 6371.341796875\n",
      "12 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 260.6058349609375\n",
      "12 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 9483.009765625\n",
      "12 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.17\n",
      "error 226.70062255859375\n",
      "13 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.41\n",
      "error 7949.87158203125\n",
      "13 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 287.59710693359375\n",
      "13 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 9400.82421875\n",
      "13 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.26\n",
      "error 258.4915466308594\n",
      "14 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.41\n",
      "error 8882.9697265625\n",
      "14 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 292.6747741699219\n",
      "14 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 9974.4794921875\n",
      "14 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.19\n",
      "error 257.9419860839844\n",
      "15 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.41\n",
      "error 10191.6474609375\n",
      "15 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 348.10546875\n",
      "15 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 10087.05078125\n",
      "15 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.25\n",
      "error 254.16317749023438\n",
      "16 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 11702.201171875\n",
      "16 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 346.7781982421875\n",
      "16 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 10274.1103515625\n",
      "16 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.19\n",
      "error 247.01502990722656\n",
      "17 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 11614.453125\n",
      "17 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 353.6601257324219\n",
      "17 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 10707.361328125\n",
      "17 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.20\n",
      "error 250.61341857910156\n",
      "18 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.39\n",
      "error 10142.822265625\n",
      "18 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 282.1038818359375\n",
      "18 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 11575.6357421875\n",
      "18 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.30\n",
      "error 255.10302734375\n",
      "19 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 11655.36328125\n",
      "19 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 273.7667236328125\n",
      "19 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 12500.556640625\n",
      "19 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.20\n",
      "error 268.74114990234375\n",
      "20 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.41\n",
      "error 12037.330078125\n",
      "20 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 278.042236328125\n",
      "20 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 13935.30859375\n",
      "20 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.20\n",
      "error 282.6186828613281\n",
      "21 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 12375.837890625\n",
      "21 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 275.3954772949219\n",
      "21 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 15060.9951171875\n",
      "21 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.21\n",
      "error 283.67840576171875\n",
      "22 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 11598.642578125\n",
      "22 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 213.49993896484375\n",
      "22 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 15884.5185546875\n",
      "22 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.20\n",
      "error 292.3230285644531\n",
      "23 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 12663.7958984375\n",
      "23 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 207.34286499023438\n",
      "23 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 16921.34765625\n",
      "23 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.21\n",
      "error 314.57818603515625\n",
      "24 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 12746.47265625\n",
      "24 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 247.91465759277344\n",
      "24 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 18076.44140625\n",
      "24 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.20\n",
      "error 315.8557434082031\n",
      "25 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 13114.31640625\n",
      "25 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 230.86358642578125\n",
      "25 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 19241.953125\n",
      "25 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.19\n",
      "error 332.0620422363281\n",
      "26 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 12857.9365234375\n",
      "26 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 228.7596893310547\n",
      "26 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 20112.20703125\n",
      "26 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.19\n",
      "error 360.31451416015625\n",
      "27 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.39\n",
      "error 13345.29296875\n",
      "27 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 301.9107666015625\n",
      "27 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 20797.279296875\n",
      "27 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.21\n",
      "error 417.1062316894531\n",
      "28 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.38\n",
      "error 14731.28515625\n",
      "28 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 440.28106689453125\n",
      "28 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 20284.41796875\n",
      "28 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.15\n",
      "error 529.7552490234375\n",
      "29 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.40\n",
      "error 14368.10546875\n",
      "29 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 366.4473571777344\n",
      "29 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.64\n",
      "error 18792.76171875\n",
      "29 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.16\n",
      "error 729.8279418945312\n",
      "30 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.41\n",
      "error 12088.884765625\n",
      "30 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.61\n",
      "error 441.53466796875\n",
      "30 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 13230.681640625\n",
      "30 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.18\n",
      "error 724.875732421875\n",
      "31 attn.Wqkv\n",
      "Pruning ...\n",
      "time 2.43\n",
      "error 455.68243408203125\n",
      "31 attn.out_proj\n",
      "Pruning ...\n",
      "time 0.60\n",
      "error 90.8716812133789\n",
      "31 ffn.up_proj\n",
      "Pruning ...\n",
      "time 0.65\n",
      "error 802.5172119140625\n",
      "31 ffn.down_proj\n",
      "Pruning ...\n",
      "time 4.18\n",
      "error 34.84049987792969\n"
     ]
    }
   ],
   "source": [
    "mpt_sequential(mpt, train_dataloader, MAX_SEQ_LEN, \"cuda\", sparsegpt_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Serialize Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path_to_save = \"./run-0-50sparse\"\n",
    "os.makedirs(path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying adapt_tokenizer.py...\n",
      "Copying attention.py...\n",
      "Copying blocks.py...\n",
      "Copying config.json...\n",
      "Copying configuration_mpt.py...\n",
      "Copying custom_embedding.py...\n",
      "Copying flash_attn_triton.py...\n",
      "Copying generation_config.json...\n",
      "Copying hf_prefixlm_converter.py...\n",
      "Copying meta_init_context.py...\n",
      "Copying modeling_mpt.py...\n",
      "Copying norm.py...\n",
      "Copying param_init_fns.py...\n",
      "Copying special_tokens_map.json...\n",
      "Copying tokenizer.json...\n",
      "Copying tokenizer_config.json...\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "\n",
    "files_to_copy = [\n",
    "    \"adapt_tokenizer.py\",\n",
    "    \"attention.py\",\n",
    "    \"blocks.py\",\n",
    "    \"config.json\",\n",
    "    \"configuration_mpt.py\",\n",
    "    \"custom_embedding.py\",\n",
    "    \"flash_attn_triton.py\",\n",
    "    \"generation_config.json\",\n",
    "    \"hf_prefixlm_converter.py\",\n",
    "    \"meta_init_context.py\",\n",
    "    \"modeling_mpt.py\",\n",
    "    \"norm.py\",\n",
    "    \"param_init_fns.py\",\n",
    "    \"special_tokens_map.json\",\n",
    "    \"tokenizer.json\",\n",
    "    \"tokenizer_config.json\",\n",
    "]\n",
    "\n",
    "for f in files_to_copy:\n",
    "    print(f\"Copying {f}...\")\n",
    "    shutil.copyfile(os.path.join(model_path, f), os.path.join(path_to_save, f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpt.save_pretrained(path_to_save)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reload Model and Confirm Its Running Nicely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----- HERE: INITIALIZE MODEL -----\n",
      "You are using config.init_device='cpu', but you can also use config.init_device=\"meta\" with Composer + FSDP for fast initialization.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f01b55130c84075be4d3c4ab8b6f3f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "\n",
    "mpt2 = AutoModelForCausalLM.from_pretrained(path_to_save, trust_remote_code=True)\n",
    "tokenizer2 = AutoTokenizer.from_pretrained(path_to_save)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:0 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?Weng earned $12/hour * 50 minutes = $<<12*50=600>>600.\n",
      "#### 600<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "prompt = \"Weng earns $12 an hour for babysitting. Yesterday, she just did 50 minutes of babysitting. How much did she earn?\"\n",
    "inputs = tokenizer2(prompt, return_tensors=\"pt\")\n",
    "\n",
    "generated_ids = mpt2.generate(**inputs, max_new_tokens=50, eos_token_id=tokenizer2.eos_token_id)\n",
    "print(tokenizer2.batch_decode(generated_ids)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sparsity distribution:\n",
      "transformer.wte.weight = 0.00 %\n",
      "transformer.blocks.0.norm_1.weight = 0.00 %\n",
      "transformer.blocks.0.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.0.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.0.norm_2.weight = 0.00 %\n",
      "transformer.blocks.0.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.0.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.1.norm_1.weight = 0.00 %\n",
      "transformer.blocks.1.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.1.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.1.norm_2.weight = 0.00 %\n",
      "transformer.blocks.1.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.1.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.2.norm_1.weight = 0.00 %\n",
      "transformer.blocks.2.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.2.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.2.norm_2.weight = 0.00 %\n",
      "transformer.blocks.2.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.2.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.3.norm_1.weight = 0.00 %\n",
      "transformer.blocks.3.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.3.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.3.norm_2.weight = 0.00 %\n",
      "transformer.blocks.3.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.3.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.4.norm_1.weight = 0.00 %\n",
      "transformer.blocks.4.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.4.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.4.norm_2.weight = 0.00 %\n",
      "transformer.blocks.4.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.4.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.5.norm_1.weight = 0.00 %\n",
      "transformer.blocks.5.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.5.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.5.norm_2.weight = 0.00 %\n",
      "transformer.blocks.5.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.5.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.6.norm_1.weight = 0.00 %\n",
      "transformer.blocks.6.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.6.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.6.norm_2.weight = 0.00 %\n",
      "transformer.blocks.6.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.6.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.7.norm_1.weight = 0.00 %\n",
      "transformer.blocks.7.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.7.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.7.norm_2.weight = 0.00 %\n",
      "transformer.blocks.7.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.7.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.8.norm_1.weight = 0.00 %\n",
      "transformer.blocks.8.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.8.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.8.norm_2.weight = 0.00 %\n",
      "transformer.blocks.8.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.8.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.9.norm_1.weight = 0.00 %\n",
      "transformer.blocks.9.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.9.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.9.norm_2.weight = 0.00 %\n",
      "transformer.blocks.9.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.9.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.10.norm_1.weight = 0.00 %\n",
      "transformer.blocks.10.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.10.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.10.norm_2.weight = 0.00 %\n",
      "transformer.blocks.10.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.10.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.11.norm_1.weight = 0.00 %\n",
      "transformer.blocks.11.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.11.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.11.norm_2.weight = 0.00 %\n",
      "transformer.blocks.11.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.11.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.12.norm_1.weight = 0.00 %\n",
      "transformer.blocks.12.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.12.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.12.norm_2.weight = 0.00 %\n",
      "transformer.blocks.12.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.12.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.13.norm_1.weight = 0.00 %\n",
      "transformer.blocks.13.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.13.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.13.norm_2.weight = 0.00 %\n",
      "transformer.blocks.13.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.13.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.14.norm_1.weight = 0.00 %\n",
      "transformer.blocks.14.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.14.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.14.norm_2.weight = 0.00 %\n",
      "transformer.blocks.14.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.14.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.15.norm_1.weight = 0.00 %\n",
      "transformer.blocks.15.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.15.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.15.norm_2.weight = 0.00 %\n",
      "transformer.blocks.15.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.15.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.16.norm_1.weight = 0.00 %\n",
      "transformer.blocks.16.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.16.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.16.norm_2.weight = 0.00 %\n",
      "transformer.blocks.16.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.16.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.17.norm_1.weight = 0.00 %\n",
      "transformer.blocks.17.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.17.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.17.norm_2.weight = 0.00 %\n",
      "transformer.blocks.17.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.17.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.18.norm_1.weight = 0.00 %\n",
      "transformer.blocks.18.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.18.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.18.norm_2.weight = 0.00 %\n",
      "transformer.blocks.18.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.18.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.19.norm_1.weight = 0.00 %\n",
      "transformer.blocks.19.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.19.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.19.norm_2.weight = 0.00 %\n",
      "transformer.blocks.19.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.19.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.20.norm_1.weight = 0.00 %\n",
      "transformer.blocks.20.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.20.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.20.norm_2.weight = 0.00 %\n",
      "transformer.blocks.20.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.20.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.21.norm_1.weight = 0.00 %\n",
      "transformer.blocks.21.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.21.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.21.norm_2.weight = 0.00 %\n",
      "transformer.blocks.21.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.21.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.22.norm_1.weight = 0.00 %\n",
      "transformer.blocks.22.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.22.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.22.norm_2.weight = 0.00 %\n",
      "transformer.blocks.22.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.22.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.23.norm_1.weight = 0.00 %\n",
      "transformer.blocks.23.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.23.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.23.norm_2.weight = 0.00 %\n",
      "transformer.blocks.23.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.23.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.24.norm_1.weight = 0.00 %\n",
      "transformer.blocks.24.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.24.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.24.norm_2.weight = 0.00 %\n",
      "transformer.blocks.24.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.24.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.25.norm_1.weight = 0.00 %\n",
      "transformer.blocks.25.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.25.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.25.norm_2.weight = 0.00 %\n",
      "transformer.blocks.25.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.25.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.26.norm_1.weight = 0.00 %\n",
      "transformer.blocks.26.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.26.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.26.norm_2.weight = 0.00 %\n",
      "transformer.blocks.26.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.26.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.27.norm_1.weight = 0.00 %\n",
      "transformer.blocks.27.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.27.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.27.norm_2.weight = 0.00 %\n",
      "transformer.blocks.27.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.27.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.28.norm_1.weight = 0.00 %\n",
      "transformer.blocks.28.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.28.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.28.norm_2.weight = 0.00 %\n",
      "transformer.blocks.28.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.28.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.29.norm_1.weight = 0.00 %\n",
      "transformer.blocks.29.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.29.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.29.norm_2.weight = 0.00 %\n",
      "transformer.blocks.29.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.29.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.30.norm_1.weight = 0.00 %\n",
      "transformer.blocks.30.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.30.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.30.norm_2.weight = 0.00 %\n",
      "transformer.blocks.30.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.30.ffn.down_proj.weight = 50.00 %\n",
      "transformer.blocks.31.norm_1.weight = 0.00 %\n",
      "transformer.blocks.31.attn.Wqkv.weight = 50.00 %\n",
      "transformer.blocks.31.attn.out_proj.weight = 50.00 %\n",
      "transformer.blocks.31.norm_2.weight = 0.00 %\n",
      "transformer.blocks.31.ffn.up_proj.weight = 50.00 %\n",
      "transformer.blocks.31.ffn.down_proj.weight = 50.00 %\n",
      "transformer.norm_f.weight = 0.00 %\n",
      "lm_head.weight = 0.00 %\n"
     ]
    }
   ],
   "source": [
    "print_sparsity(mpt2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# acc == 0.235"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
